# MALT: Malware Analysis Literature-survey Tool

[![Build Status](https://travis-ci.org/joemccann/dillinger.svg?branch=master)](https://travis-ci.org/joemccann/dillinger)

MALT is a tool to perform literature surveys given a list of papers. Here we include a stepwise procedures to replicate and update the database, replicate the webapplication and download pdf papers for further analysis.

Running Example: https://malware-analysis-survey.herokuapp.com/

# Features 
  - Query and Analyse a rich collection of publications for Automatic Malware Analysis.
  - Collect Bibliographical data of publications
  - Collect Full-text version of papers

You can also:
  - Modify the scripts to do exploratory studies on different research topics.
  


### Tech

MALT uses a  couple of open source projects and APIs to work properly:

* [Scholarly](https://github.com/percolator/scholarly) - A python based scrapper to retrieve Google Scholar Data.

* [DBLP](https://dblp.uni-trier.de/faq/13501473) - An API to query DBLP.

* [scidownl](https://pypi.org/project/scidownl/) - A python wrapper for Sci-Hub open API.

* [Django](https://www.djangoproject.com/) - An open source web application framework written in Python.

* [D3.js](https://d3js.org/) - A JavaScript library used to create interactive visualizations in the browser.

## 1.Database

The scripts are written for MySQL database. We use postgres for deployment on Heroku, you can follow the guidelines [here](https://devcenter.heroku.com/articles/heroku-mysql#:~:text=MySQL%20is%20a%20popular%20relational,that%20currently%20run%20on%20MySQL) to migrate.

Install and setup MySQL. 
- Follow the guidelines [here](https://dev.mysql.com/doc/mysql-installation-excerpt/5.7/en/) for installation.
- After installing, start the MySql Client

 ```sh
$ sudo mysql -u root
```
- Create a new database and switch to it.
```sh
mysql> Create database forensics;
mysql> Use forensics
```
- Import the database
```sh
mysql> source forensics.sql 
```

## 2. Scripts

The script folder contains the Python 3.6 scrapper scripts used to collect bibliographical data. 
We also recommend using a VPN to perform multiple queries. Please use a VPN server from an English speaking country (US, UK, Canada). If you are a linux user we recommend using a free version of command line VPN, Windscribe (https://windscribe.com/guides/linux).


Install the required Python packages.

```sh
$ pip3 install requirements.txt
```

1.  [googleScholar.py]:  Google Scholar to retrieve remaining attributes and check for papers in the citedBy. If paper is present in citedBy and our table, I inserted a row in the citedBy table. The citedBy results are stored in the JSON file.

```sh 
Example: The script takes two arguments Paper Index and Server Index 
$ python3 googleScholar.py  0 0
[usage: googleScholar.py [options] paper_index server_index]
Here we start from 0th paper and 0th VPN server. When the script isn't able to retrieve more papers, restart the script with the last paper index and increment the server by 1.
```

2.  [dblp.py]: Used to query DBLP to retrieve additional attributes (Authors and DoI) and missing attribute (year and url).

```sh
$ python3 dblp.py
```

3. [pdf2text.py]: Used to collect fulltext version of papers given their DOI and convert them to text.

```sh
$ python3 pdf2text.py
```


## 3. Web-Application


The web-application is hosted on Heroku and can be hosted locally as well. D3.js Force-directed graph is used to represent who cites whom in the given set of papers.


License
----

MIT




  

